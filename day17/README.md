# Day 17: Code Analysis Pipeline with AI Chat

**AI-powered code analysis pipeline integrated into interactive chat interface**

## Overview

This project implements a multi-stage data processing pipeline for analyzing source code. The pipeline combines static analysis with AI-powered insights, all accessible through an interactive chat interface.

## Key Features

### ğŸ” Code Analysis Pipeline
- **4-stage processing**: Metadata extraction â†’ Static analysis â†’ AI documentation â†’ Quality assessment
- **Multi-language support**: Python, JavaScript, TypeScript, Java, Go, Rust, C++
- **Intelligent metrics**: Complexity, code smells, security issues, quality scoring
- **AI-powered insights**: Gemini AI generates documentation and improvement suggestions

### ğŸ’¬ Interactive Chat Integration
- **Integrated analysis**: Run `/analyze <file>` directly in chat
- **AI conversation**: Ask questions about analyzed code
- **Context-aware responses**: AI remembers analysis results
- **Report export**: Save analysis reports to files

### ğŸ“Š Analysis Metrics
- Code/comment/blank line counts
- Function and class extraction
- Cyclomatic complexity
- Code smell detection
- Security vulnerability scanning
- Quality score (0-100)

## Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input: Source Code File            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Metadata Extraction       â”‚
â”‚  â€¢ Language detection               â”‚
â”‚  â€¢ Line counting                    â”‚
â”‚  â€¢ Function/class extraction        â”‚
â”‚  â€¢ Import analysis                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: Static Analysis           â”‚
â”‚  â€¢ Complexity calculation           â”‚
â”‚  â€¢ Code smell detection             â”‚
â”‚  â€¢ Issue identification             â”‚
â”‚  â€¢ Security checks                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: AI Documentation          â”‚
â”‚  â€¢ Gemini AI analysis               â”‚
â”‚  â€¢ Code summary generation          â”‚
â”‚  â€¢ Pattern detection                â”‚
â”‚  â€¢ Improvement suggestions          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 4: Quality Assessment        â”‚
â”‚  â€¢ Score calculation (0-100)        â”‚
â”‚  â€¢ Recommendations                  â”‚
â”‚  â€¢ Priority ranking                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output: Comprehensive Report       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
day17/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ code_analyzer.py           # Core analysis stages
â”‚   â”œâ”€â”€ pipeline_executor.py       # Pipeline orchestrator
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ gemini_client.py           # Gemini API client
â”‚   â”œâ”€â”€ conversation.py            # Conversation management
â”‚   â”œâ”€â”€ storage.py                 # SQLite persistence
â”‚   â””â”€â”€ text_manager.py            # Text processing utilities
â”œâ”€â”€ test_samples/
â”‚   â”œâ”€â”€ sample1_good.py            # Well-written code example
â”‚   â”œâ”€â”€ sample2_bad.py             # Code with issues example
â”‚   â””â”€â”€ sample3_javascript.js      # JavaScript example
â”œâ”€â”€ results/                        # Analysis reports (generated)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ conversations.db           # Chat history database
â”œâ”€â”€ chat.py                        # Main interactive chat
â”œâ”€â”€ analyze_code.py                # Standalone CLI tool
â”œâ”€â”€ demo.sh                        # Demo script
â”œâ”€â”€ README.md             # Detailed pipeline docs
â””â”€â”€ requirements.txt
```

## Installation

1. **Clone and navigate:**
```bash
cd day17
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Set up API key:**
```bash
export GEMINI_API_KEY="your-api-key-here"
```

## Usage

### Interactive Chat Mode (Recommended)

```bash
python3 chat.py
```

**Available commands:**
```
/analyze <file>        - Analyze a code file
/save-report <file>    - Save last analysis report
/resume                - Load previous conversation
/clear                 - Start new conversation
/model                 - Change AI model
/help                  - Show all commands
/quit                  - Exit
```

**Example workflow:**
```
You: /analyze test_samples/sample1_good.py

[Pipeline runs and shows beautiful formatted results]

ğŸ“Š Code Metadata
â”œâ”€ Language: python
â”œâ”€ Code lines: 88
â”œâ”€ Functions: 11
â””â”€ Classes: 1

ğŸ¯ Quality Score: 99/100 â­ Excellent

You: Why is the quality score so high?

AI: Your code scored 99/100 because it demonstrates excellent
    practices: well-modularized functions averaging 8 lines each,
    good complexity score of 1, and clear naming conventions...

You: How can I make it even better?

AI: To reach 100/100, consider:
    1. Adding docstrings to all functions
    2. Replacing magic numbers with named constants...

You: /save-report results/analysis.txt
âœ“ Report saved to: results/analysis.txt
```

### Standalone CLI Mode

```bash
# Basic analysis
python3 analyze_code.py my_code.py

# With AI documentation
python3 analyze_code.py my_code.py

# Save to file
python3 analyze_code.py my_code.py -o report.txt

# JSON format
python3 analyze_code.py my_code.py -o report.json -f json

# Quick check without AI
python3 analyze_code.py my_code.py --brief --no-ai
```

### Demo Script

```bash
./demo.sh
```

Shows analysis of all three sample files with explanations.

## Example Analysis Results

### Sample 1: Good Code
```
ğŸ“Š Metadata: 88 lines, 11 functions, 1 class
ğŸ¯ Score: 99/100 â­ Excellent
ğŸ”¬ Complexity: 1
ğŸ’¡ Recommendations: Add more comments
```

### Sample 2: Problematic Code
```
ğŸ“Š Metadata: 82 lines, 9 functions, 1 class
ğŸ¯ Score: 89/100 âœ… Good
ğŸ”¬ Complexity: 4
âš ï¸  Issues: 3 (1 high-severity)
ğŸ’¡ Recommendations:
    â€¢ Fix eval() usage (security risk)
    â€¢ Refactor repetitive if/elif chains
    â€¢ Add docstrings
```

### Sample 3: JavaScript
```
ğŸ“Š Metadata: 77 lines, 2 functions, 1 class
ğŸ¯ Score: 97/100 â­ Excellent
ğŸ”¬ Complexity: 2
ğŸ’¡ Recommendations: Extract magic numbers
```

## Quality Scoring System

**Score components:**
- âœ… **+5**: Good comment ratio (>20%)
- âœ… **+5**: Well-modularized (<30 lines/function avg)
- âš ï¸ **-5**: Moderate complexity (10-20)
- âš ï¸ **-15**: High complexity (>20)
- âš ï¸ **-3 per code smell**
- âš ï¸ **-5 per medium issue**
- âš ï¸ **-10 per high-severity issue**

**Ratings:**
- 90-100: â­ Excellent
- 75-89: âœ… Good
- 60-74: âš ï¸ Fair
- <60: âŒ Needs Improvement

## Pipeline Design Pattern

This implementation demonstrates the **Pipeline Pattern** for data processing:

1. **Sequential stages**: Data flows through distinct processing steps
2. **Modular components**: Each stage is independent and reusable
3. **Composable**: Easy to add/remove/reorder stages
4. **Testable**: Each stage can be tested independently
5. **Hybrid approach**: Combines classical algorithms + AI

### Why This Architecture?

- **Classical stages (1,2,4)**: Fast, deterministic, no API costs
- **AI stage (3)**: Provides insights humans would give
- **Best of both worlds**: Speed + intelligence

## Technical Details

### Dependencies
- `requests` - HTTP client for Gemini API
- `rich` - Terminal formatting and tables
- Standard library: `re`, `pathlib`, `dataclasses`

### Performance
- Metadata extraction: ~50ms
- Static analysis: ~100ms
- AI documentation: 2-5 seconds
- **Total: ~3-6 seconds per file**

### Limitations
- Requires valid syntax (won't analyze broken code)
- Large files (>10k lines) may be slower
- AI analysis requires internet connection
- Some language features may not be detected

## Advanced Usage

### Custom Analysis Pipeline

```python
from pipeline import CodeAnalysisPipeline, MetadataExtractor

# Create custom pipeline
pipeline = CodeAnalysisPipeline()

# Analyze code
result = pipeline.analyze_file('my_code.py')

# Access results
print(f"Quality: {result.quality_score}")
print(f"Complexity: {result.static_analysis.complexity_score}")
for smell in result.static_analysis.code_smells:
    print(f"  - {smell}")
```

### Batch Analysis

```python
import glob
from pipeline import CodeAnalysisPipeline

pipeline = CodeAnalysisPipeline()

for file in glob.glob('src/**/*.py', recursive=True):
    result = pipeline.analyze_file(file)
    if result.quality_score < 70:
        print(f"âš ï¸ {file}: {result.quality_score:.1f}")
```

## Chat Features

### Persistent Storage
- All conversations saved to SQLite
- Resume any previous analysis session
- Full history of all analyses

### AI Context Awareness
After `/analyze`, AI knows:
- Code structure and metrics
- Detected issues and smells
- Quality score breakdown
- Can answer specific questions about YOUR code

### Example Interaction
```
You: /analyze my_api.py
[Analysis runs...]

You: Why did I get penalized for complexity?
AI: Your complexity score is 18, which is in the "moderate"
    range (10-20). The main contributors are:
    - handle_request() function has 8 decision points
    - Nested if/elif chains in validate_input()
    ...

You: How should I refactor handle_request?
AI: Consider using a strategy pattern or command pattern...
```

## Learning Outcomes

This project demonstrates:

1. **Pipeline Pattern**: Multi-stage data processing
2. **Hybrid AI**: Combining classical algorithms + LLM
3. **Modular Design**: Reusable, testable components
4. **Rich UI**: Professional terminal interfaces
5. **Context Management**: AI remembers analysis state
6. **Error Handling**: Graceful degradation
7. **File I/O**: Reading/writing reports

## References

- [Google Gemini API](https://ai.google.dev/) - Gemini API documentation
- [Rich Library](https://rich.readthedocs.io/) - Terminal formatting
- [Requests](https://docs.python-requests.org/) - HTTP library
- [SQLite3](https://docs.python.org/3/library/sqlite3.html) - Python SQLite documentation

---

## License

Educational project for AI Advent Challenge
