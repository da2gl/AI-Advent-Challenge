version: '3.8'

services:
  god-agent:
    build: .
    container_name: god-agent
    ports:
      - "8080:8080"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - LLM_PROVIDER=${LLM_PROVIDER:-gemini}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - PORT=8080
    volumes:
      - ./data:/app/data
      - ./mcp_integration/config.json:/app/mcp_integration/config.json
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - god-agent-network

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    networks:
      - god-agent-network
    # Optional: GPU support (uncomment if you have NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # Optional: Redis for caching
  redis:
    image: redis:7-alpine
    container_name: god-agent-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    networks:
      - god-agent-network
    command: redis-server --appendonly yes

  # Optional: Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: god-agent-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    restart: unless-stopped
    networks:
      - god-agent-network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

volumes:
  ollama-data:
  redis-data:
  prometheus-data:

networks:
  god-agent-network:
    driver: bridge
